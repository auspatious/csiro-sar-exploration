kind: Workflow

metadata:
  generateName: s1-geomad-
  namespace: csa-sar-capability-argo

spec:
  entrypoint: workflow-entrypoint
  serviceAccountName: csa-sar-capability-team-sa-argo
  artifactGC:
    strategy: OnWorkflowDeletion
    forceFinalizerRemoval: true
  nodeSelector:
    nodegroup: data_pipelines
  tolerations:
    - key: easi.csiro.au/dedicated
      operator: Equal
      effect: NoSchedule
      value: data_pipelines
  parallelism: 10
  arguments:
    parameters:
      - name: image-name
        value: "ghcr.io/auspatious/csiro-sar-exploration" # The Docker image
      - name: image-tag
        value: "0.0.0-19-g087711f" # The Docker image and code version
      - name: version
        value: "0.3.0" # The version of the data product being made
      - name: input-product
        value: "sentinel1_grd_gamma0_beta"
      - name: temporal-range
        value: "2023--P1Y"
      - name: frequency
        value: "annual"
      - name: grid
        value: "au-30"
      - name: output-product-name
        value: csiro_s1_mosaic_annual
      - name: output-bucket
        value: easihub-csiro-dc-data-projects # The bucket where the data will be stored
      - name: output-path
        value: sar-capability/csiro_s1_mosaic_annual # The prefix of the path where the data will be stored
      - name: config
        value: |
          plugin: s1_geomad.plugin.S1GeoMAD
          product:
            name: {{workflow.parameters.output-product-name}}
            short_name: {{workflow.parameters.output-product-name}}
            version: {{workflow.parameters.version}}
            product_family: sentinel-1
            collections_site: explorer.csiro.easi-eo.solutions
            region_code_format: "x{x:03d}y{y:03d}"
          plugin_config:
            chunks:
              longitude: 2000
              latitude: 2000
            geomad_work_chunks: [600, 600]
          max_processing_time: 600
          s3_acl: bucket-owner-full-control
          aws_unsigned: false
          overwrite: true
  templates:
    - name: workflow-entrypoint
      dag:
        tasks:
          - name: process
            template: process
            arguments:
              parameters:
                - name: tile-id
                  value: "2023--P1Y,38,9"
                - name: version
                  value: "{{ workflow.parameters.version }}"
                - name: output-bucket
                  value: "{{ workflow.parameters.output-bucket }}"
                - name: output-path
                  value: "{{ workflow.parameters.output-path }}"
                - name: config
                  value: "{{ workflow.parameters.config }}"

    - name: process
      inputs:
        parameters:
          - name: tile-id
          - name: version
          - name: output-bucket
          - name: output-path
          - name: config
        artifacts:
          - name: db
            path: /tmp/job.db
            s3:
              endpoint: s3.amazonaws.com
              key: "{{workflow.parameters.output-path}}/{{workflow.parameters.version}}/job-{{workflow.parameters.temporal-range}}.db.tgz"
              bucket: "{{workflow.parameters.output-bucket}}"
      container:
        image: "{{ workflow.parameters.image-name }}:{{ workflow.parameters.image-tag }}"
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            memory: 50Gi
            cpu: 12
          limits:
            cpu: 16
            memory: 60Gi
        command: ["/bin/bash"]
        args:
          - "-c"
          - |
            odc-stats run \
              --apply_eodatasets3 \
              --config="{{inputs.parameters.config}}" \
              --threads="16" \
              --memory-limit="60GB" \
              --location="s3://{{inputs.parameters.output-bucket}}/{{inputs.parameters.output-path}}/{{workflow.parameters.version}}/" \
              /tmp/job.db \
              {{ inputs.parameters.tile-id }}
